{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15150>,\n",
      " 'elevation': 3.0,\n",
      " 'id': 1,\n",
      " 'latitude': 21.2716,\n",
      " 'longitude': -157.8168,\n",
      " 'name': 'WAIKIKI 717.2, HI US',\n",
      " 'station': 'USC00519397'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15350>,\n",
      " 'elevation': 14.6,\n",
      " 'id': 2,\n",
      " 'latitude': 21.4234,\n",
      " 'longitude': -157.8015,\n",
      " 'name': 'KANEOHE 838.1, HI US',\n",
      " 'station': 'USC00513117'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e153d0>,\n",
      " 'elevation': 7.0,\n",
      " 'id': 3,\n",
      " 'latitude': 21.5213,\n",
      " 'longitude': -157.8374,\n",
      " 'name': 'KUALOA RANCH HEADQUARTERS 886.9, HI US',\n",
      " 'station': 'USC00514830'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15450>,\n",
      " 'elevation': 11.9,\n",
      " 'id': 4,\n",
      " 'latitude': 21.3934,\n",
      " 'longitude': -157.9751,\n",
      " 'name': 'PEARL CITY, HI US',\n",
      " 'station': 'USC00517948'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e154d0>,\n",
      " 'elevation': 306.6,\n",
      " 'id': 5,\n",
      " 'latitude': 21.4992,\n",
      " 'longitude': -158.0111,\n",
      " 'name': 'UPPER WAHIAWA 874.3, HI US',\n",
      " 'station': 'USC00518838'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15590>,\n",
      " 'elevation': 19.5,\n",
      " 'id': 6,\n",
      " 'latitude': 21.33556,\n",
      " 'longitude': -157.71139,\n",
      " 'name': 'WAIMANALO EXPERIMENTAL FARM, HI US',\n",
      " 'station': 'USC00519523'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15650>,\n",
      " 'elevation': 32.9,\n",
      " 'id': 7,\n",
      " 'latitude': 21.45167,\n",
      " 'longitude': -157.84888999999998,\n",
      " 'name': 'WAIHEE 837.5, HI US',\n",
      " 'station': 'USC00519281'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15710>,\n",
      " 'elevation': 0.9,\n",
      " 'id': 8,\n",
      " 'latitude': 21.3152,\n",
      " 'longitude': -157.9992,\n",
      " 'name': 'HONOLULU OBSERVATORY 702.2, HI US',\n",
      " 'station': 'USC00511918'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e157d0>,\n",
      " 'elevation': 152.4,\n",
      " 'id': 9,\n",
      " 'latitude': 21.3331,\n",
      " 'longitude': -157.8025,\n",
      " 'name': 'MANOA LYON ARBO 785.2, HI US',\n",
      " 'station': 'USC00516128'}\n"
     ]
    }
   ],
   "source": [
    "# Import Hawaii Station Data\n",
    "\n",
    "from station_model import Hawaii_Station\n",
    "\n",
    "engine_s = create_engine(\"sqlite:///hawaii.sqlite\")\n",
    "conn_s = engine_s.connect()\n",
    "session_s = Session(bind=engine_s)\n",
    "\n",
    "station_data = session_s.query(Hawaii_Station).limit(10)\n",
    "for row in station_data:\n",
    "    pprint(row.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15e10>,\n",
      " 'elevation': 3.0,\n",
      " 'id': 1,\n",
      " 'latitude': 21.2716,\n",
      " 'longitude': -157.8168,\n",
      " 'name': 'WAIKIKI 717.2, HI US',\n",
      " 'station': 'USC00519397'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15f50>,\n",
      " 'elevation': 14.6,\n",
      " 'id': 2,\n",
      " 'latitude': 21.4234,\n",
      " 'longitude': -157.8015,\n",
      " 'name': 'KANEOHE 838.1, HI US',\n",
      " 'station': 'USC00513117'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15cd0>,\n",
      " 'elevation': 7.0,\n",
      " 'id': 3,\n",
      " 'latitude': 21.5213,\n",
      " 'longitude': -157.8374,\n",
      " 'name': 'KUALOA RANCH HEADQUARTERS 886.9, HI US',\n",
      " 'station': 'USC00514830'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15c10>,\n",
      " 'elevation': 11.9,\n",
      " 'id': 4,\n",
      " 'latitude': 21.3934,\n",
      " 'longitude': -157.9751,\n",
      " 'name': 'PEARL CITY, HI US',\n",
      " 'station': 'USC00517948'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15fd0>,\n",
      " 'elevation': 306.6,\n",
      " 'id': 5,\n",
      " 'latitude': 21.4992,\n",
      " 'longitude': -158.0111,\n",
      " 'name': 'UPPER WAHIAWA 874.3, HI US',\n",
      " 'station': 'USC00518838'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15310>,\n",
      " 'elevation': 19.5,\n",
      " 'id': 6,\n",
      " 'latitude': 21.33556,\n",
      " 'longitude': -157.71139,\n",
      " 'name': 'WAIMANALO EXPERIMENTAL FARM, HI US',\n",
      " 'station': 'USC00519523'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e15390>,\n",
      " 'elevation': 32.9,\n",
      " 'id': 7,\n",
      " 'latitude': 21.45167,\n",
      " 'longitude': -157.84888999999998,\n",
      " 'name': 'WAIHEE 837.5, HI US',\n",
      " 'station': 'USC00519281'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e153d0>,\n",
      " 'elevation': 0.9,\n",
      " 'id': 8,\n",
      " 'latitude': 21.3152,\n",
      " 'longitude': -157.9992,\n",
      " 'name': 'HONOLULU OBSERVATORY 702.2, HI US',\n",
      " 'station': 'USC00511918'}\n",
      "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x7fdf46e157d0>,\n",
      " 'elevation': 152.4,\n",
      " 'id': 9,\n",
      " 'latitude': 21.3331,\n",
      " 'longitude': -157.8025,\n",
      " 'name': 'MANOA LYON ARBO 785.2, HI US',\n",
      " 'station': 'USC00516128'}\n"
     ]
    }
   ],
   "source": [
    "# Import Hawaii Measurement Data\n",
    "\n",
    "from measurement_model import Hawaii_Measurement\n",
    "\n",
    "engine_m = create_engine(\"sqlite:///hawaii.sqlite\")\n",
    "conn_m = engine_m.connect()\n",
    "session_m = Session(bind=engine_m)\n",
    "\n",
    "measurement_data = session_m.query(Hawaii_Measurement).limit(10)\n",
    "for row in station_data:\n",
    "    pprint(row.__dict__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    max(date)\n",
      "0  2017-08-23\n"
     ]
    }
   ],
   "source": [
    "# Design a query to retrieve the last 12 months of precipitation data and plot the results\n",
    "# Calculate the date 1 year ago from the last data point in the database\n",
    "# Get the last 12 months of data\n",
    "\n",
    "measurement_df1 = pd.read_sql(\"SELECT * FROM measurement\", conn_m).dropna(how = 'any') \n",
    "# print(measurement_df1)\n",
    "# print(measurement_df1.head())\n",
    "\n",
    "# Get max date from table\n",
    "max_df = pd.read_sql(\"SELECT max(date) FROM measurement\", conn_m)\n",
    "print(max_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id      station        date  prcp  tobs\n",
      "0   1  USC00519397  2010-01-01  0.08  65.0\n",
      "1   2  USC00519397  2010-01-02  0.00  63.0\n",
      "2   3  USC00519397  2010-01-03  0.00  74.0\n",
      "3   4  USC00519397  2010-01-04  0.00  76.0\n",
      "5   6  USC00519397  2010-01-07  0.06  70.0\n"
     ]
    }
   ],
   "source": [
    "# Perform a query to retrieve the data and precipitation scores\n",
    "# Save the query results as a Pandas DataFrame\n",
    "\n",
    "measurement_df2 = pd.read_sql(\"\"\"\n",
    "SELECT date, prcp \n",
    "FROM measurement \n",
    "WHERE date between '2016-08-23' and '2017-08-23'\n",
    "\"\"\", conn_m)\n",
    "# print(measurement_df1)\n",
    "print(measurement_df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            prcp\n",
      "date            \n",
      "2016-08-23  0.00\n",
      "2016-08-23  1.79\n",
      "2016-08-23  0.05\n",
      "2016-08-23  0.15\n",
      "2016-08-23  0.70\n"
     ]
    }
   ],
   "source": [
    "# Set the index to the date column and sort the dataframe by date\n",
    "\n",
    "measurement_df3 = measurement_df2.sort_values(by = 'date').dropna(how = 'any').set_index('date')\n",
    "print(measurement_df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              prcp\n",
      "count  2021.000000\n",
      "mean      0.177279\n",
      "std       0.461190\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.020000\n",
      "75%       0.130000\n",
      "max       6.700000\n"
     ]
    }
   ],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n",
    "print(measurement_df2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas Plotting with Matplotlib to plot the data\n",
    "\n",
    "measurement_df2.plot(\n",
    "    x=\"date\",\n",
    "    y='prcp',\n",
    "    kind=\"bar\",\n",
    "    title=\"Precipitation\"\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Inches\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_df2.plot.bar(x = 'date', y = 'prcp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to show how many stations are available in this dataset?\n",
    "\n",
    "# Get all station data\n",
    "station_count = pd.read_sql(\"SELECT COUNT(station) FROM station\",conn_s)\n",
    "# print(station_count)\n",
    "print(station_count.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most active stations? (i.e. what stations have the most rows)?\n",
    "# List the stations and the counts in descending order.\n",
    "\n",
    "# all_df = pd.read_sql(\"SELECT sub.* FROM (SELECT m.id, m.station, date, prcp, tobs, name, latitude, longitude, elevation, COUNT(m.station) as station_count FROM measurement AS m LEFT OUTER JOIN station AS s ON m.station = s.station GROUP BY m.id, m.station, date, prcp, tobs, name, latitude, longitude, elevation) as sub ORDER BY station_count\", conn_m).dropna(how = 'any') \n",
    "all_df = pd.read_sql(\"\"\"\n",
    "SELECT sub.* \n",
    "FROM (\n",
    "        SELECT m.station, COUNT(m.station) as station_count \n",
    "        FROM measurement AS m \n",
    "            LEFT OUTER JOIN station AS s ON m.station = s.station \n",
    "            GROUP BY m.station\n",
    "            ) as sub\n",
    "ORDER BY station_count desc\n",
    "\"\"\", conn_m).dropna(how = 'any') \n",
    "print(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to retrieve the last 12 months of temperature observation data (TOBS).\n",
    "# Filter by the station with the highest number of observations.\n",
    "\n",
    "tobs_df = pd.read_sql(\"\"\"\n",
    "SELECT station, date, tobs\n",
    "FROM measurement \n",
    "WHERE station = 'USC00519281' and date between '2016-08-23' and '2017-08-23'\n",
    "\"\"\", conn_m).dropna(how = 'any') \n",
    "print(tobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results as a histogram with bins=12\n",
    "\n",
    "tobs_df.hist(bins=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "\n",
    "# function usage example\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
